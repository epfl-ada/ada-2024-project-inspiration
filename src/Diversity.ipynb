{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diversity: \n",
    "1. Reorganise ethnicities into a few groups\n",
    "2. Establish the Naive Coefficient\n",
    "3. Add the multiplication by extra coefficient rewarding equal representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Start by making the character_df\n",
    "NB: final name should be \"filtered_character\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the dataframe is:(450668, 13)\n",
      "Index(['975900', '/m/03vyhn', '2001-08-24', 'Akooshay', '1958-08-26', 'F',\n",
      "       '1.62', 'Unnamed: 7', 'Wanda De Jesus', '42', '/m/0bgchxw',\n",
      "       '/m/0bgcj3x', '/m/03wcfv7'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "character_metadata = pd.read_csv('../data/character.metadata.tsv', sep='\\t')\n",
    "\n",
    "# Look through the DataFrames:\n",
    "print(f'the size of the dataframe is:{character_metadata.shape}') #-- (450668, 13)\n",
    "print(character_metadata.columns) #need to rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "new_column_names = [\n",
    "    \"Wikipedia_movie_ID\",\n",
    "    \"Freebase_movie_ID\",\n",
    "    \"Movie_release_date\",\n",
    "    \"Character_name\",\n",
    "    \"Actor_date_of_birth\",\n",
    "    \"Actor_gender\",\n",
    "    \"Actor_height_m\",\n",
    "    \"Actor_ethnicity\",\n",
    "    \"Actor_name\",\n",
    "    \"Actor_age_at_movie_release\",\n",
    "    \"Freebase_character_actor_map_ID\",\n",
    "    \"Freebase_character_ID\",\n",
    "    \"Freebase_actor_ID\"\n",
    "]\n",
    "character_metadata.columns = new_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows for 'Wikipedia_movie_ID': 450668\n",
      "Remaining rows for 'Movie_release_date': 440673\n",
      "Remaining rows for 'Actor_ethnicity': 106058\n"
     ]
    }
   ],
   "source": [
    "columns_to_check = ['Wikipedia_movie_ID', 'Movie_release_date', 'Actor_ethnicity']\n",
    "remaining_rows = {col: character_metadata[col].dropna().shape[0] for col in columns_to_check}\n",
    "for col, count in remaining_rows.items():\n",
    "    print(f\"Remaining rows for '{col}': {count}\")\n",
    "\n",
    "filtered_character = character_metadata[['Wikipedia_movie_ID', 'Movie_release_date', 'Actor_ethnicity']].dropna(subset=['Actor_ethnicity']) # no missing value remaining in each col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#homogeneous release dates (only the year)\n",
    "filtered_character['Movie_release_date'] = filtered_character['Movie_release_date'].astype(str).str[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dataframe, but with freebase_id for ethnicity. We define the function to find the right labels corresponding to the id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fb_to_label(freebase_id,conversion_table):\n",
    "    if freebase_id in conversion_table.index:\n",
    "        return conversion_table.loc[freebase_id,'label']\n",
    "    else:\n",
    "        return None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found a table online with freebase_id, wikidata_id & Label\n",
    "We import it, but it has 2 million lines --> we will select only the lines we need, i.e. the lines of the ethnicity id we have in our filtered_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the file, setting freebase_id as index allows us to use .loc later\n",
    "fb_wiki_gen = pd.read_csv('../data/fb_wiki_mapping.tsv',sep='\\t')\n",
    "fb_wiki_gen.set_index('freebase_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make list of different existing ethnicities\n",
    "ethnicities_list = filtered_character['Actor_ethnicity'].unique().tolist()\n",
    "#now select those from the fb_wiki_gen\n",
    "fb_wiki_ethnic = fb_wiki_gen.loc[fb_wiki_gen.index.isin(ethnicities_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can now change the Actor_ethnicity column from freebase_id to label\n",
    "filtered_character['Actor_ethnicity']=filtered_character['Actor_ethnicity'].apply(fb_to_label,conversion_table=fb_wiki_ethnic)\n",
    "#some freebase_ids couldn't be found, so we get None. We will now drop those None values\n",
    "filtered_character = filtered_character.dropna(subset=['Actor_ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Movie_release_date</th>\n",
       "      <th>Actor_ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221935</th>\n",
       "      <td>7657105</td>\n",
       "      <td>1994</td>\n",
       "      <td>Irish Americans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140759</th>\n",
       "      <td>7323790</td>\n",
       "      <td>1980</td>\n",
       "      <td>Jewish people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184660</th>\n",
       "      <td>15402569</td>\n",
       "      <td>2008</td>\n",
       "      <td>Jewish people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122693</th>\n",
       "      <td>684771</td>\n",
       "      <td>1998</td>\n",
       "      <td>Welsh people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406098</th>\n",
       "      <td>435566</td>\n",
       "      <td>1996</td>\n",
       "      <td>Italian Americans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Wikipedia_movie_ID Movie_release_date    Actor_ethnicity\n",
       "221935             7657105               1994    Irish Americans\n",
       "140759             7323790               1980      Jewish people\n",
       "184660            15402569               2008      Jewish people\n",
       "122693              684771               1998       Welsh people\n",
       "406098              435566               1996  Italian Americans"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_character.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the right dataframe to Analyse diversity, but we have too many different ethnicities. We want to remove the very specific ones and group them together in more general ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Key:\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openai.api_key = ''\n",
    "\n",
    "#openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
